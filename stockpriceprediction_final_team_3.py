# -*- coding: utf-8 -*-
"""StockPricePrediction Final Team 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AHIJ52OOCHMXzFvgaUFlqeD77kJSANkA
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
import plotly.express as px
import plotly.graph_objs as go
import plotly.io as pio
import statsmodels.api as sm
import warnings
warnings.filterwarnings("ignore")

pip install --upgrade yfinance

amazon = yf.download("AMZN", period='10y', interval="1wk")
amazon.reset_index(inplace=True)

amazon.to_csv("raw_amazon_data.csv", index=False)

print(amazon.head())
print(amazon.describe())

amazon.dropna(inplace=True)

"""Feature Selection"""

amazon['Price Change'] = amazon['Close'] - amazon['Open']
amazon['Volatility'] = amazon['High'] - amazon['Low']
amazon['Average Price'] = (amazon['High'] + amazon['Low']) / 2
amazon['Return'] = amazon['Close'].pct_change()
amazon['Log Return'] = np.log(amazon['Close'] / amazon['Close'].shift(1))

amazon['MA_4'] = amazon['Close'].rolling(window=4).mean()
amazon['MA_12'] = amazon['Close'].rolling(window=12).mean()

amazon['EMA_4'] = amazon['Close'].ewm(span=4, adjust=False).mean()
amazon['EMA_12'] = amazon['Close'].ewm(span=12, adjust=False).mean()

delta = amazon['Close'].diff()
gain = delta.where(delta > 0, 0)
loss = -delta.where(delta < 0, 0)
avg_gain = gain.rolling(window=14).mean()
avg_loss = loss.rolling(window=14).mean()
rs = avg_gain / avg_loss
amazon['RSI'] = 100 - (100 / (1 + rs))

exp1 = amazon['Close'].ewm(span=12, adjust=False).mean()
exp2 = amazon['Close'].ewm(span=26, adjust=False).mean()
amazon['MACD'] = exp1 - exp2
amazon['Signal Line'] = amazon['MACD'].ewm(span=9, adjust=False).mean()

amazon.dropna(inplace=True)

amazon.to_csv("feature_engineered_amazon_data.csv", index=False)
print("File saved as feature_engineered_amazon_data.csv")

ts = amazon[['Date', 'Close']].copy()
ts.set_index('Date', inplace=True)

"""Stationarity Check"""

from statsmodels.tsa.stattools import adfuller
result = adfuller(ts['Close'])
print(f"ADF Statistic: {result[0]}")
print(f"p-value: {result[1]}")
if result[1] > 0.05:
    print("Series is non-stationary. Differencing will be applied.")
    ts_diff = ts['Close'].diff().dropna()
else:
    print("Series is stationary.")
    ts_diff = ts['Close']

"""Visualization"""

plt.figure(figsize=(12,6))
plt.plot(amazon['Date'], amazon['Close'], label='Close Price', color='blue')
plt.title('Amazon Stock Price Over Time')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.grid()
plt.legend()
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(amazon.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

plt.figure(figsize=(12,6))
plt.plot(amazon['Date'], amazon['Close'], label='Close Price')
plt.plot(amazon['Date'], amazon['MA_4'], label='MA 4 Weeks')
plt.plot(amazon['Date'], amazon['MA_12'], label='MA 12 Weeks')
plt.title('Moving Averages')
plt.legend()
plt.show()

plt.figure(figsize=(12,6))
plt.plot(amazon['Date'], amazon['Volatility'], color='orange')
plt.title('Weekly Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.grid()
plt.show()

plt.figure(figsize=(12,6))
plt.plot(amazon['Date'], amazon['RSI'], label='RSI', color='purple')
plt.axhline(70, linestyle='--', color='red', alpha=0.5)
plt.axhline(30, linestyle='--', color='green', alpha=0.5)
plt.title('Relative Strength Index (RSI)')
plt.legend()
plt.show()

"""ARIMA"""

from statsmodels.tsa.arima.model import ARIMA

model_arima = ARIMA(ts_diff, order=(5,1,0))
arima_fit = model_arima.fit()
forecast_arima = arima_fit.forecast(steps=30)

plt.figure(figsize=(10,5))
plt.plot(ts_diff, label='Actual')
plt.plot(forecast_arima, label='ARIMA Forecast', color='red')
plt.title("ARIMA Forecast (30 Weeks Ahead)")
plt.legend()
plt.show()

"""SARIMA"""

from statsmodels.tsa.statespace.sarimax import SARIMAX

model_sarima = SARIMAX(ts_diff, order=(1,1,1), seasonal_order=(1,1,1,52))  # assuming seasonality ~ yearly
sarima_fit = model_sarima.fit()
forecast_sarima = sarima_fit.forecast(steps=30)

plt.figure(figsize=(10,5))
plt.plot(ts_diff, label='Actual')
plt.plot(forecast_sarima, label='SARIMA Forecast', color='green')
plt.title("SARIMA Forecast (30 Weeks Ahead)")
plt.legend()
plt.show()

pip install prophet

"""PROPHET"""

# Prophet Model

df_prophet = amazon[['Date', 'Close']].copy()


df_prophet['ds'] = pd.to_datetime(df_prophet['Date'])
df_prophet['y'] = df_prophet['Close']


df_prophet = df_prophet[['ds', 'y']].dropna()


from prophet import Prophet
model_prophet = Prophet()
model_prophet.fit(df_prophet)


future = model_prophet.make_future_dataframe(periods=30, freq='W')
forecast = model_prophet.predict(future)


fig = model_prophet.plot(forecast)
plt.title('Amazon Stock Price Forecast with Prophet')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.show()

"""LSTM MODEL"""

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

Close_data = amazon[['Close']].copy()

# Normalize the data
scaler = MinMaxScaler()
numerical_features = amazon.select_dtypes(include=['number']).columns
scaled_data = scaler.fit_transform(amazon[numerical_features])

# Create sequences
def create_sequences(amazon, seq_length):
    X, y = [], []
    for i in range(seq_length, len(amazon)):
        X.append(amazon[i-seq_length:i])
        y.append(amazon[i])
    return np.array(X), np.array(y)

SEQ_LEN = 60
X, y = create_sequences(scaled_data, SEQ_LEN)

# Train-test split
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# Build LSTM model
model = Sequential([
    LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error')

# Train
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Predictions
predicted = model.predict(X_test)
predicted_2D = predicted.reshape(-1, 1)  # Reshape to (n_samples, 1)
predicted_expanded = np.repeat(predicted_2D, y_test.shape[1], axis=1) # Repeat to match y_test shape

predicted_prices = scaler.inverse_transform(predicted_expanded)
real_prices = scaler.inverse_transform(y_test)

# Plot
plt.figure(figsize=(12, 6))
line1, = plt.plot(real_prices[:,0], color='blue', label='Actual Price')
line2, = plt.plot(predicted_prices[:,0], color='red', label='Predicted Price')
plt.title('Amazon Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Price')
plt.ylabel('Price')
plt.legend(handles=[line1, line2])
plt.show()

print(len(real_prices), len(predicted_prices))

!pip install keras-tuner

from keras_tuner import RandomSearch
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

def build_model(hp):
    model = Sequential()
    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32),
                   return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(hp.Float('dropout1', 0.1, 0.5)))
    model.add(LSTM(units=hp.Int('units2', min_value=32, max_value=128, step=32)))
    model.add(Dropout(hp.Float('dropout2', 0.1, 0.5)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

tuner = RandomSearch(build_model, objective='val_loss', max_trials=5, directory='lstm_tuning', project_name='stock')

tuner.search(X_train, y_train, epochs=20, validation_split=0.2)
best_model = tuner.get_best_models(num_models=1)[0]

# Save in the new Keras format
model.save('best_lstm_model.keras')

import keras

keras.saving.save_model(model, 'best_lstm_model.keras')